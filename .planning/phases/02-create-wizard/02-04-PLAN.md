---
phase: 02-create-wizard
plan: 04
type: execute
---

<objective>
Build Step 3: Script HITL editor with AI-generated narration script that users can edit.

Purpose: Generate engaging narration script using property data + image context, allow agents to refine their property's story.
Output: Script generation via GPT-4 and editable text areas (MVP-critical HITL feature).
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
./02-04-SUMMARY.md
~/.claude/get-shit-done/references/checkpoints.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Prior plan context:
@.planning/phases/02-create-wizard/02-01-SUMMARY.md
@.planning/phases/02-create-wizard/02-02-SUMMARY.md

# Existing wizard implementation:
@src/lib/wizard/types.ts
@src/lib/wizard/wizard-context.tsx
@src/lib/openai.ts
@src/app/(protected)/create/page.tsx
@src/components/wizard/steps/upload-step.tsx

**Key context from prior work:**
- Images have `label` (e.g., "Master Suite with Coffered Ceiling") and `features` array (e.g., ["Walk-in closet", "Ocean view"])
- These image labels and features should inform script generation
- PropertyData includes address, specs, and neighborhood POIs (features array)
- ScriptSection type has: id, imageId, content, duration, order

**Design decision:**
Script sections are per-image (matching video sequence), not 5 fixed sections. Each image gets a brief narration segment (~3-5 seconds of audio, ~15-25 words). Total video duration scales with image count.

**MVP-Critical:** This is the HITL (Human-in-the-Loop) feature that differentiates the product. Agents must be able to edit the AI-generated script before video generation.
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create script generation API endpoint</name>
  <files>src/app/api/script/generate/route.ts</files>
  <action>
Create POST /api/script/generate endpoint:

Input (from wizard state):
- propertyData: { address, city, state, price, beds, baths, sqft, propertyType, description, features (POIs) }
- images: [{ id, label, features, roomType }]

Output: { sections: ScriptSection[] }

Each section maps to an image with:
- id: nanoid
- imageId: matching image ID
- content: narration text (~20-30 words for ~4-5 seconds of audio)
- duration: estimated seconds (calculate from word count / 3)
- order: matches image order

GPT-4 prompt should:
1. Generate opening line for first image that hooks viewer (mention property type + key feature)
2. For each interior image: use the image label and features to craft natural narration
3. Reference neighborhood POIs naturally in middle sections
4. End with CTA mentioning agent/listing

Example output for image "Gourmet Kitchen with Marble Island":
"Step into a chef's dreamâ€”this stunning gourmet kitchen features imported marble countertops and professional-grade appliances perfect for entertaining."

Keep each section concise for voiceover. Use luxury/aspirational language matching brand voice.
  </action>
  <verify>curl POST /api/script/generate with sample data returns sections array</verify>
  <done>API returns one ScriptSection per image with contextual narration</done>
</task>

<task type="auto">
  <name>Task 2: Create script editor component</name>
  <files>src/components/wizard/steps/script-step.tsx</files>
  <action>
Create ScriptStep component with HITL editing:

Layout:
- "Generate Script" button prominently displayed (if no sections yet)
- Loading state with writing/typing animation (Framer Motion)
- Scrollable list of script sections, each showing:
  - Thumbnail of corresponding image (from wizard state)
  - Image label as section header
  - Editable textarea with script content
  - Word count + estimated duration (words / 3 = seconds)
  - "Regenerate" button (sparkles icon) for this section only

forwardRef pattern (like PropertyDataStep):
- Expose validate() method that checks all sections have content
- Parent calls ref.validate() before allowing Next

Editing UX:
- Debounced auto-save to wizard context (500ms)
- Visual indicator when content differs from original (edited badge)
- Word count turns amber >40 words, red >60 words
- Total duration display at top: "~{X}s narration"

Update wizard context with UPDATE_SCRIPT action on changes.
  </action>
  <verify>npm run build succeeds, component renders with textareas</verify>
  <done>Script editor shows sections with thumbnails and word counts</done>
</task>

<task type="auto">
  <name>Task 3: Integrate script step into wizard flow</name>
  <files>src/app/(protected)/create/page.tsx</files>
  <action>
Replace ScriptStepPlaceholder with ScriptStep:

- Import ScriptStep and ScriptStepHandle
- Create scriptStepRef using useRef
- Render ScriptStep when currentStep === WizardStep.SCRIPT
- On handleNext for SCRIPT step: validate via scriptStepRef.current.validate()

Behavior:
- When entering step 3 with no script sections, auto-trigger generation
- Script generation uses state.propertyData and state.images
- If user goes back and changes images, offer to regenerate script
- "Regenerate All" button in step header to start fresh

Navigation:
- Back returns to Upload step (images preserved)
- Next proceeds to Style step (script persisted in state)
  </action>
  <verify>Step navigation works, script auto-generates on first visit</verify>
  <done>Script step integrated with auto-generation and validation</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>AI script generation with per-image HITL editing</what-built>
  <how-to-verify>
    1. Run: npm run dev
    2. Complete Steps 1-2 (enter property data, upload images with labels)
    3. Click Next to Step 3:
       - Verify script auto-generates (loading animation)
       - Verify each section shows image thumbnail + label header
       - Verify word count and duration estimates display
       - Edit one section - verify word count updates live
       - Verify changes persist after navigating back and forward
       - Click "Regenerate" on one section - verify only that section updates
    4. Confirm: Script content references property features and image labels
  </how-to-verify>
  <resume-signal>Type "approved" to continue, or describe issues to fix</resume-signal>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `npm run build` succeeds
- [ ] Script generation produces one section per image
- [ ] Sections reference property data and image features
- [ ] All sections are editable with word counts
- [ ] Changes persist in wizard state
- [ ] Human verified HITL experience
</verification>

<success_criteria>

- All 4 tasks completed (including checkpoint)
- All verification checks pass
- Script quality uses luxury real estate voice
- Editing UX is intuitive for non-technical users
- Per-image script sections match video sequence
</success_criteria>

<output>
After completion, create `.planning/phases/02-create-wizard/02-04-SUMMARY.md`
</output>
